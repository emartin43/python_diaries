{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156292ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install os\n",
    "%pip install pandas\n",
    "%pip install openpyxl\n",
    "%pip install datetime\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os \n",
    "import openpyxl\n",
    "import datetime\n",
    "\n",
    "from openpyxl import load_workbook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241a3a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SAVE .XLS to .XLSX\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the parent folder containing subfolders with .xls files\n",
    "parent_folder_path = r'\\\\fs109\\es-comm\\Commercial_Share_Folder\\Bright Rebates\\BPA Lighting Calculator Extraction Tool - Rosetta\\ExcelLightCalcInbox\\Pre 2019'\n",
    "\n",
    "# Specify the destination folder path for .xlsx files\n",
    "destination_folder_path = r'\\\\fs109\\ES-Comm\\Commercial_Share_Folder\\Bright Rebates\\BPA Lighting Calculator Extraction Tool - Rosetta\\output_file'\n",
    "\n",
    "# Iterate over subfolders in the parent folder\n",
    "for subfolder_name in os.listdir(parent_folder_path):\n",
    "    subfolder_path = os.path.join(parent_folder_path, subfolder_name)\n",
    "\n",
    "    # Check if the subfolder is a directory\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Get a list of all files in the subfolder\n",
    "        file_list = os.listdir(subfolder_path)\n",
    "\n",
    "        # Loop through each file in the subfolder\n",
    "        for file_name in file_list:\n",
    "            # Check if the file is a .xls file\n",
    "            if file_name.endswith('.xls'):\n",
    "                xls_path = os.path.join(subfolder_path, file_name)\n",
    "\n",
    "                try:\n",
    "                    # Read specific sheets from the .xls file \n",
    "                    df = pd.read_excel(xls_path, sheet_name=[\"user_Lighting Details\", \"UploadData\"])\n",
    "                    \n",
    "                    # Concatenate the DataFrames in the dictionary into a single DataFrame\n",
    "                    combined_df = pd.concat(df.values(), ignore_index=True)\n",
    "                    \n",
    "                    # Define the new file name with \"loop_\" prefix and .xlsx extension\n",
    "                    new_file_name = \"loop_\" + os.path.splitext(file_name)[0] + \".xlsx\"\n",
    "\n",
    "                    # Save the DataFrame as .xlsx with the new file name in the destination folder\n",
    "                    new_xlsx_path = os.path.join(destination_folder_path, new_file_name)\n",
    "                    combined_df.to_excel(new_xlsx_path, index=False)\n",
    "\n",
    "                    print(f\"Converted '{file_name}' to '{new_file_name}' and saved to destination folder\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing '{file_name}': {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e446213",
   "metadata": {},
   "outputs": [],
   "source": [
    "##DATA MANIPULATION TO HAVE ALL INFO IN ONE SHEET\n",
    "\n",
    "import os\n",
    "import openpyxl\n",
    "\n",
    "# Specify the folder containing the Excel files\n",
    "folder_path = r'\\\\fs109\\ES-Comm\\Commercial_Share_Folder\\Bright Rebates\\BPA Lighting Calculator Extraction Tool - Rosetta\\output_file'\n",
    "\n",
    "# List the Excel files in the folder\n",
    "excel_files = [file for file in os.listdir(folder_path) if file.endswith('.xlsx')]\n",
    "\n",
    "# Iterate through each Excel file in the folder\n",
    "for excel_file in excel_files:\n",
    "    # Open the workbook\n",
    "    workbook = openpyxl.load_workbook(os.path.join(folder_path, excel_file))\n",
    "\n",
    "    # Choose the sheet \n",
    "    sheet = workbook['Sheet1']\n",
    "\n",
    "    # Iterate through the cells in the sheet\n",
    "    for row in sheet.iter_rows():\n",
    "        for cell in row:\n",
    "            # Check if the cell contains 'Retrofit'\n",
    "            if cell.value == 'Retrofit':\n",
    "                # Set the initial source cell to one column to the left of the cell containing 'Retrofit'\n",
    "                source_cell = sheet.cell(row=cell.row, column=cell.column - 1)\n",
    "\n",
    "                # Set the initial destination cell to Z9\n",
    "                destination_cell = sheet['Z9']\n",
    "\n",
    "                # Iterate through 28 columns to the right\n",
    "                for col_index in range(1, 29):\n",
    "                    # Move the value from the source cell to the destination cell\n",
    "                    destination_cell.value = source_cell.value\n",
    "\n",
    "                    # Clear the source cell \n",
    "                    source_cell.value = None\n",
    "\n",
    "                    # Move both the source and destination cells right one column\n",
    "                    source_cell = sheet.cell(row=source_cell.row, column=source_cell.column + 1)\n",
    "                    destination_cell = sheet.cell(row=destination_cell.row, column=destination_cell.column + 1)\n",
    "\n",
    "                # Delete the cell that contained 'Retrofit'\n",
    "                sheet.delete_rows(cell.row)\n",
    "\n",
    "    # Save the changes to the Excel file\n",
    "    workbook.save(os.path.join(folder_path, excel_file))\n",
    "\n",
    "    # Close the workbook\n",
    "    workbook.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48503aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Here defining function that scrapes excel spreadsheets and saves them individually\n",
    "\n",
    "\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def process_and_combine_data(source_file_path, output_file_path):\n",
    "    sheet_name = \"Sheet1\"\n",
    "\n",
    "    source_workbook = openpyxl.load_workbook(source_file_path, data_only=True)\n",
    "    source_sheet = source_workbook[sheet_name]\n",
    "\n",
    "    # existing code for extracting cell_values and cell_names here...\n",
    "    \n",
    "    # Extracted cell values\n",
    "    cell_values = [\n",
    "        source_sheet['P2'].value,\n",
    "        source_sheet['P4'].value, source_sheet['P5'].value, source_sheet['P6'].value, source_sheet['P7'].value,\n",
    "        source_sheet['P3'].value,\n",
    "        source_sheet['U4'].value,\n",
    "        source_sheet['U5'].value,\n",
    "        source_sheet['P10'].value,\n",
    "        source_sheet['P11'].value,\n",
    "        source_sheet['P12'].value,\n",
    "        source_sheet['S10'].value,\n",
    "        source_sheet['S11'].value,\n",
    "        source_sheet['S12'].value,\n",
    "        source_sheet['S13'].value,\n",
    "        source_sheet['V10'].value.split(\":\")[1].strip() if source_sheet['V10'].value else \" \",  # Check if V10 is empty\n",
    "        source_sheet['V11'].value.split(\":\")[1].strip() if source_sheet['V11'].value else \" \",\n",
    "        source_sheet['V12'].value.split(\":\")[1].strip() if source_sheet['V12'].value else \" \",\n",
    "        source_sheet['Q15'].value, source_sheet['Q16'].value, source_sheet['Q17'].value, source_sheet['Q18'].value,\n",
    "        source_sheet['Q19'].value,source_sheet['AE9'].value, source_sheet['AF9'].value, source_sheet['AG9'].value, source_sheet['AH9'].value, \n",
    "        source_sheet['AI9'].value, source_sheet['AJ9'].value, source_sheet['AL9'].value, source_sheet['AS9'].value,\n",
    "        source_sheet['AU9'].value,\n",
    "        source_sheet['AV9'].value, source_sheet['AW9'].value, source_sheet['BA9'].value, source_sheet['BB9'].value, source_sheet['BC9'].value\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Define cell names for the columns in the output file\n",
    "    cell_names = [\n",
    "        'project_name', 'mailing_address', 'mailing_city_state_zip', 'contact_phone', 'contact_email',\n",
    "        'company_name', 'project/site_address', 'project/site_city_state_zip', 'tpu_contact_name', 'tpu_contact_phone', 'tpu_email', 'ta_organization',\n",
    "        'ta_contact_name', 'ta_contact_phone', 'ta_contact_email',\n",
    "        'class', 'energy_rate_($/kWh)', 'energy_rate_($/kW)', 'est_annual_energy_savings', 'est_energy_savings_(%)', 'est_annual_utility_bill_savings', 'est_total_proj_install_costs', 'est_total_proj_incentive',\n",
    "        'projcost', 'busbr_sav', 'wattred', 'totcred', 'bc_ratio', 'bldg_type', 'unique_site_id', 'fedblg', 'completion_date', 'bpa_max_wtp', 'funding_source',\n",
    "        'nwtan_member', 'neea_nxt_lvl_1', 'neea_nxt_level_2'\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Fill with empty strings to match the length of cell_names\n",
    "    cell_values += [''] * (len(cell_names) - len(cell_values))\n",
    "    \n",
    "    \n",
    "    # Extract \"mailing_address\" and \"mailing_city_state_zip\" values\n",
    "    mailing_address = source_sheet['F4'].value\n",
    "    mailing_city_state_zip = source_sheet['F5'].value\n",
    "    \n",
    "    # Extract \"project/site_address\" and \"project/site_city_state_zip\" values\n",
    "    project_site_address = source_sheet['G4'].value\n",
    "    project_site_city_state_zip = source_sheet['G5'].value\n",
    "    \n",
    "\n",
    "    # Create a DataFrame with extracted cell values and column names\n",
    "    df_existing = pd.DataFrame([cell_values], columns=cell_names)\n",
    "    \n",
    "    \n",
    "     # Define a function to combine \"mailing_address\" and \"mailing_city_state_zip\" with a separator\n",
    "    def combine_address(row):\n",
    "        return f\"{row['mailing_address']} {row['mailing_city_state_zip']}\"\n",
    "\n",
    "    # Apply the function to create a new column \"mailing_full_address\"\n",
    "    df_existing['mailing_full_address'] = df_existing.apply(combine_address, axis=1)\n",
    "    \n",
    "    # Define a function to combine \"project/site_address\" and \"project/site_city_state_zip\" with a separator\n",
    "    def combine_site_address(row):\n",
    "        return f\"{row['project/site_address']} {row['project/site_city_state_zip']}\"\n",
    "\n",
    "    # Apply the function to create a new column \"project/site_full_address\"\n",
    "    df_existing['project/site_full_address'] = df_existing.apply(combine_site_address, axis=1)\n",
    "    \n",
    "\n",
    "\n",
    "    #existing code for extracting and merging additional data here...\n",
    "    \n",
    "    # Create an empty DataFrame to store the extracted values\n",
    "    columns_to_extract = ['K', 'L', 'M', 'N', 'P', 'Q', 'R', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'AA', 'AB', 'AC', 'AD'\n",
    "                         , 'AE', 'AF', 'AG', 'AH', 'AI', 'AJ', 'AK', 'AL', 'AM', 'AN', 'AO', 'AP', 'AQ', 'AR', 'AS', \n",
    "                          'AT', 'AU', 'AV', 'AW', 'AX', 'AY', 'AZ', 'BA', 'BB', 'BC', 'BD', 'BE', 'BF', 'BG', 'BH', \n",
    "                          'BI', 'BJ', 'BK', 'BL', 'BM', 'BN', 'BO', 'BP', 'BQ', 'BR', 'BS', 'BT', 'BU', 'BV', 'BW', 'BX', \n",
    "                          'BY', 'BZ', 'CA', 'CB', 'CC', 'CD', 'CE', 'CF', 'CG', 'CH', 'CI', 'CJ', 'CK', 'CL', 'CM', 'CN', \n",
    "                          'CO', 'CP', 'CQ', 'CR', 'CS', 'CT', 'CU', 'CV', 'CW', 'CX', 'CY', 'CZ', 'DA', 'DB', 'DC', 'DD', \n",
    "                          'DE', 'DF', 'DG', 'DH', 'DI', 'DJ', 'DK', 'DL', 'DM', 'DN', 'DO', 'DP', 'DQ', 'DR', 'DS', 'DT', \n",
    "                          'DU', 'DV', 'DW', 'DX', 'DY', 'DZ', 'EA', 'EB', 'EC', 'ED', 'EE', 'EF', 'EG', 'EH', 'EI', 'EJ', \n",
    "                          'EK', 'EL', 'EM', 'EN', 'EO', 'EP', 'EQ', 'ER', 'ES', 'ET', 'EU', 'EV', 'EW', 'EX', 'EY', 'EZ', \n",
    "                          'FA', 'FB', 'FC', 'FD', 'FE', 'FF'\n",
    "]\n",
    "    df_existing2 = pd.DataFrame(columns=columns_to_extract + [''])\n",
    "\n",
    "    # Initialize a variable to keep track of the row index\n",
    "    row_index = 22  # Start from row 22 (assuming 1-based index)\n",
    "\n",
    "    # Get the value from cell P2 of the source sheet\n",
    "    project_name_value = source_sheet['P2'].value\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Loop through each row in the source sheet\n",
    "    while True:\n",
    "        # Extract values from columns K to FF for the current row\n",
    "        values = [\n",
    "            source_sheet[f'{col}{row_index}'].value\n",
    "            for col in columns_to_extract\n",
    "        ]\n",
    "    \n",
    "        # Check if all values in the extracted row are None (blank)\n",
    "        if all(value is None for value in values):\n",
    "            break  # Break the loop if an entirely blank row is found\n",
    "    \n",
    "        #Add the value from project_name and the extracted values to df_existing2\n",
    "        df_existing2.loc[len(df_existing2)] = values + ['']\n",
    "    \n",
    "        # Move to the next row\n",
    "        row_index += 1\n",
    "\n",
    "    # Create a new DataFrame by repeating df_existing based on the length of df_existing2\n",
    "    repeated_df_existing = pd.concat([df_existing] * len(df_existing2), ignore_index=True)\n",
    "\n",
    "    # Concatenate the two DataFrames side by side\n",
    "    df_combined = pd.concat([repeated_df_existing, df_existing2], axis=1)\n",
    "\n",
    "    # existing code for renaming columns \n",
    "    \n",
    "    # Define the path to the folder containing the files\n",
    "    folder_path = r'\\\\fs109\\es-comm\\Commercial_Share_Folder\\Bright Rebates\\BPA Lighting Calculator Extraction Tool - Rosetta\\ExcelLightCalcInbox\\Pre 2019'  \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Rename columns in df_existing\n",
    "    column_rename_dict = {\n",
    "        'K': 'measure_no', 'L': 'status', 'M': 'space', 'N': 'annual_hrs',\n",
    "        'P': 'existing', 'Q': 'proposed', 'R': 'controls', 'T': 'kWh/year',\n",
    "        'U': 'watts_per_fixture', 'V': 'incentives', 'W': 'notes', 'X': 'blank_column', 'Y': 'kw_for_table', 'Z': 'space', \n",
    "        'AA': 'existing_quantity', 'AB': 'existing_class', 'AC': 'existing_type', 'AD': 'existing_subtype', \n",
    "        'AE': 'existing_lamp_wattage', 'AF': 'existing_lamps_per_fixture', 'AG': 'proposed_measure_type', \n",
    "        'AH': 'proposed_quantity', 'AI': 'proposed_class', 'AJ': 'proposed_type', 'AK': 'proposed_subtype', \n",
    "        'AL': 'proposed_lamp_wattage', 'AM': 'proposed_lamps_per_fixture', 'AN': 'proposed_lamp_model_number', \n",
    "        'AO': 'proposed_ballast_model_number', 'AP': 'no_controls', 'AQ': 'controls_quantity', 'AR': 'controls_class', \n",
    "        'AS': 'controls_percent_reduction', 'AT': 'notes', 'AU': 'number_of_errors', 'AV': 'existing_mml_row', \n",
    "        'AW': 'proposed_mml_row', 'AX': 'existing_ballast_factor', 'AY': 'proposed_ballast_factor', \n",
    "        'AZ': 'existing_fixture_wattage', 'BA': 'proposed_fixture_wattage', 'BB': 'arith_fixture_wattage', \n",
    "        'BC': 'electric_interaction', 'BD': 'gas_interaction', 'BE': 'existing_fixture_kwh_base', \n",
    "        'BF': 'arith_existing_fixture_kwh_base', 'BG': 'proposed_fixture_kwh_base', 'BH': 'decommissioned_fixtures', \n",
    "        'BI': 'precond_decom_kwh_savings', 'BJ': 'arith_decom_kwh_savings', 'BK': 'precond_equip_kwh_savings', \n",
    "        'BL': 'arith_equip_kwh_savings', 'BM': 'precond_controls_kwh_savings', 'BN': 'arith_controls_kwh_savings', \n",
    "        'BO': 'precond_decom_and_equip_kwh_savings', 'BP': 'arith_decom_and_equip_kwh_savings', \n",
    "        'BQ': 'precond_total_kwh_savings', 'BR': 'arith_total_kwh_savings', 'BS': 'precond_equip_and_controls_kwh_savings',\n",
    "        'BT': 'arith_equip_and_controls_kwh_savings', 'BU': 'precond_equip_and_controls_percent_savings', \n",
    "        'BV': 'arith_equip_and_controls_percent_savings', 'BW': 'precond_measure_percent_savings', \n",
    "        'BX': 'arith_measure_percent_savings', 'BY': 'precond_measure_kw', 'BZ': 'arith_measure_kw', \n",
    "        'CA': 'proposed_measure_kw', 'CB': 'precond_kw_savings', 'CC': 'arith_kw_savings', \n",
    "        'CD': 'existing_fixture_kwh_with_hvac', 'CE': 'arith_existing_fixture_kwh_with_hvac', \n",
    "        'CF': 'proposed_fixture_kwh_with_hvac', 'CG': 'precond_decom_kwh_savings_with_hvac', \n",
    "        'CH': 'arith_decom_kwh_savings_with_hvac', 'CI': 'precond_equip_kwh_savings_with_hvac', \n",
    "        'CJ': 'arith_equip_kwh_savings_with_hvac', 'CK': 'precond_equip_and_controls_kwh_savings_with_hvac', \n",
    "        'CL': 'arith_equip_and_controls_kwh_savings_with_hvac', 'CM': 'precond_controls_kwh_savings_with_hvac', \n",
    "        'CN': 'arith_controls_kwh_savings_with_hvac', 'CO': 'precond_decom_and_equip_kwh_savings_with_hvac',\n",
    "        'CP': 'arith_decom_and_equip_kwh_savings_with_hvac', 'CQ': 'precond_total_kwh_savings_with_hvac', \n",
    "        'CR': 'arith_total_kwh_savings_with_hvac', 'CS': 'existing_fixture_kwh_with_hvac_busbar', \n",
    "        'CT': 'arith_existing_fixture_kwh_with_hvac_busbar', 'CU': 'proposed_fixture_kwh_with_hvac_busbar', \n",
    "        'CV': 'precond_decom_kwh_savings_with_hvac_busbar', 'CW': 'arith_decom_kwh_savings_with_hvac_busbar', 'CX': 'precond_equip_kwh_savings_with_hvac_busbar', 'CY': 'arith_equip_kwh_savings_with_hvac_busbar', 'CZ': 'precond_equip_and_controls_kwh_savings_with_hvac_busbar', 'DA': 'arith_equip_and_controls_kwh_savings_with_hvac_busbar', 'DB': 'precond_controls_kwh_savings_with_hvac_busbar', 'DC': 'arith_controls_kwh_savings_with_hvac_busbar', 'DD': 'precond_decom_and_equip_kwh_savings_with_hvac_busbar', 'DE': 'arith_decom_and_equip_kwh_savings_with_hvac_busbar', 'DF': 'precond_total_kwh_savings_with_hvac_busbar', 'DG': 'arith_total_kwh_savings_with_hvac_busbar', 'DH': 'precond_total_measure_kwh_with_hvac_busbar', 'DI': 'arith_total_measure_kwh_with_hvac_busbar', 'DJ': 'proposed_total_measure_kwh_with_hvac_busbar', 'DK': 'therms_increase_precond', 'DL': 'therms_increase_arith', 'DM': 'decom_incentive_rates', 'DN': 'utility_decom_incentive_rate', 'DO': 'bpa_decom_incentive_rate', 'DP': 'nonstandard_incentive_rates', 'DQ': 'utility_nonstandard_incentive_rate', 'DR': 'bpa_nonstandard_incentive_rate', 'DS': 'controls_incentive_quantity', 'DT': 'controls_incentive_utility', 'DU': 'controls_incentive_bpa', 'DV': 'controls_text', 'DW': 'controls_incentive_vector', 'DX': 'controls_incentive', 'DY': 'bpa_controls_incentive_rate', 'DZ': 'utility_controls_incentive_rate', 'EA': 'decom_incentive_quantity', 'EB': 'decom_incentive_utility', 'EC': 'decom_incentive_bpa', 'ED': 'equipment_incentive_quantity', 'EE': 'equipment_incentive_utility', 'EF': 'equipment_incentive_bpa', 'EG': 'measure_text', 'EH': 'decommissioning_and_equipment_results_text', 'EI': 'controls_results_text', 'EJ': 'precond_total_measure_kwh', 'EK': 'arith_total_measure_kwh', 'EL': 'proposed_total_measure_kwh', 'EM': 'precond_total_measure_kwh_with_hvac', 'EN': 'arith_total_measure_kwh_with_hvac', 'EO': 'proposed_total_measure_kwh_with_hvac', 'EP': 'precond_kw_percent_savings', 'EQ': 'arith_kw_percent_savings', 'ER': 'total_utility_incentive', 'ES': 'total_bpa_incentive', 'ET': 'non_standard_status', 'EU': 'status_notes', 'EV': 'control_kwh_savings', 'EW': 'note_that_this_is_actually_a_percent_savings_0_to_100', 'EX': 'utility_equipment_incentive_rate', 'EY': 'decom_and_equipment_incentive_name', 'EZ': 'decom_and_equipment_incentive_description', 'FA': 'controls_incentive_name', 'FB': 'controls_incentive_description', 'FC': 'approved_non_standard_user_field_concat', 'FD': 'space_type', 'FE': 'ref_no', 'FF': 'equals_percent_of_time_lights_are_turned_off_by_controls'\n",
    "\n",
    "\n",
    "    }\n",
    "    df_combined.rename(columns=column_rename_dict, inplace=True)\n",
    "\n",
    "\n",
    "    # Save the merged DataFrame to the output file\n",
    "    df_combined.to_excel(output_file_path, index=False)\n",
    "\n",
    "    print(f\"Data from '{source_file_path}' added to the output file '{output_file_path}'.\")\n",
    "\n",
    "\n",
    "\n",
    "# Specify the folder containing the Excel files\n",
    "folder_path = r'\\\\fs109\\ES-Comm\\Commercial_Share_Folder\\Bright Rebates\\BPA Lighting Calculator Extraction Tool - Rosetta\\output_file'\n",
    "\n",
    "# Define the folder path for the output files \n",
    "output_folder = r'\\\\fs109\\ES-Comm\\Commercial_Share_Folder\\Bright Rebates\\BPA Lighting Calculator Extraction Tool - Rosetta\\output_loop_file'\n",
    "\n",
    "\n",
    "\n",
    "# Get a list of all files in the folder\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "for file_name in file_list:\n",
    "    # Check if the file is an Excel file (assuming all files in the folder are Excel files)\n",
    "    if file_name.endswith('.xlsx') or file_name.endswith('.xls'):\n",
    "        source_file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Adjust the output file name format, using the original file name without extension as a prefix\n",
    "        output_file_name = os.path.splitext(file_name)[0] + '_output.xlsx'\n",
    "        output_file_path = os.path.join(output_folder, output_file_name)\n",
    "\n",
    "        # Call the function to process and combine data for each source file\n",
    "        process_and_combine_data(source_file_path, output_file_path)\n",
    "\n",
    "print(\"All data from the files has been processed and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd37d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##get completion date\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "# Define the date conversion function\n",
    "def convert_date(input_date):\n",
    "    # Define a mapping of month names to month numbers\n",
    "    month_mapping = {\n",
    "        'January': '01',\n",
    "        'February': '02',\n",
    "        'March': '03',\n",
    "        'April': '04',\n",
    "        'May': '05',\n",
    "        'June': '06',\n",
    "        'July': '07',\n",
    "        'August': '08',\n",
    "        'September': '09',\n",
    "        'October': '10',\n",
    "        'November': '11',\n",
    "        'December': '12'\n",
    "    }\n",
    "\n",
    "    # Define a regular expression pattern to match the date format\n",
    "    date_pattern = r'(\\w+) (\\d{1,2})(?:, )?(\\d{4})'\n",
    "\n",
    "    # Ensure that the input is a string\n",
    "    if isinstance(input_date, str):\n",
    "        # Use regular expression to extract parts\n",
    "        match = re.match(date_pattern, input_date)\n",
    "\n",
    "        if match:\n",
    "            # Extract month, day, and year\n",
    "            month, day, year = match.groups()\n",
    "\n",
    "            # Get the numeric month value from the mapping\n",
    "            month = month_mapping.get(month, '00')  \n",
    "\n",
    "            # Create the formatted date string in 'yyyy-mm-dd' format\n",
    "            formatted_date = f\"{year}-{month}-{day:02}\"\n",
    "\n",
    "            return formatted_date\n",
    "        else:\n",
    "            return input_date  # Return the original input for invalid date formats\n",
    "    else:\n",
    "        return input_date  # Return the input unchanged for non-string inputs (e.g., datetime objects)\n",
    "\n",
    "# Apply the date conversion function to the 'completion_date' column after converting it to strings\n",
    "appended_df['formatted_completion_date'] = appended_df['completion_date'].apply(lambda x: convert_date(x) if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "#convert dates to strings\n",
    "appended_df['formatted_completion_date'] = appended_df['formatted_completion_date'].astype(str)\n",
    "\n",
    "# Display the DataFrame with the formatted dates\n",
    "print(appended_df['formatted_completion_date'])\n",
    "\n",
    "\n",
    "# Define a function to remove the last 9 characters from a cell to remove timestamp manually \n",
    "def remove_last_9_characters(cell_value):\n",
    "    return cell_value[:-9]\n",
    "\n",
    "# Specify the column to modify\n",
    "column_name = 'formatted_completion_date'\n",
    "\n",
    "# Use the apply function to apply the function to the entire column\n",
    "appended_df['formatted_completion_date'] = appended_df['formatted_completion_date'].apply(remove_last_9_characters)\n",
    "\n",
    "# Specify the path for the output Excel file\n",
    "output_file_path = r'\\\\fs109\\ES-Comm\\Commercial_Share_Folder\\Bright Rebates\\BPA Lighting Calculator Extraction Tool - Rosetta\\appended_data.xlsx'\n",
    "\n",
    "# Save the appended DataFrame to a single Excel file\n",
    "appended_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"All dates have been formatted and saved to '{output_file_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##get original file path and project id, then join \n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Specify the parent folder containing subfolders with .xls files\n",
    "parent_folder_path = r'\\\\fs109\\es-comm\\Commercial_Share_Folder\\Bright Rebates\\BPA Lighting Calculator Extraction Tool - Rosetta\\ExcelLightCalcInbox\\Pre 2019'\n",
    "\n",
    "# Specify the destination folder path for .xlsx files\n",
    "destination_folder_path = r'\\\\fs109\\ES-Comm\\Commercial_Share_Folder\\Bright Rebates\\BPA Lighting Calculator Extraction Tool - Rosetta\\output_file'\n",
    "\n",
    "# Create an empty list to store the paths of converted .xlsx files\n",
    "converted_file_paths = []\n",
    "\n",
    "# Create empty lists to store parsed components (letter and number) and original .xls paths\n",
    "letters = []\n",
    "numbers = []\n",
    "xls_paths = []  # New list to store the original .xls file paths\n",
    "\n",
    "# Define the regex pattern for the 'CBR_######' or 'BIZ_######' pattern\n",
    "pattern = r'(CBR|BIZ)_\\s*(\\d{5,6})'\n",
    "\n",
    "# Iterate over subfolders in the parent folder\n",
    "for subfolder_name in os.listdir(parent_folder_path):\n",
    "    subfolder_path = os.path.join(parent_folder_path, subfolder_name)\n",
    "\n",
    "    # Check if the subfolder is a directory\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Get a list of all files in the subfolder\n",
    "        file_list = os.listdir(subfolder_path)\n",
    "\n",
    "        # Loop through each file in the subfolder\n",
    "        for file_name in file_list:\n",
    "            # Check if the file is a .xls file\n",
    "            if file_name.endswith('.xls'):\n",
    "                xls_path = os.path.join(subfolder_path, file_name)\n",
    "\n",
    "                # Read specific sheets from the .xls file\n",
    "                df = pd.read_excel(xls_path, sheet_name=[\"user_Lighting Details\", \"UploadData\"])\n",
    "                \n",
    "                # Concatenate the DataFrames in the dictionary into a single DataFrame\n",
    "                combined_df = pd.concat(df.values(), ignore_index=True)\n",
    "                \n",
    "                # Define the new file name with \"loop_\" prefix and .xlsx extension\n",
    "                new_file_name = \"loop_\" + os.path.splitext(file_name)[0] + \".xlsx\"\n",
    "\n",
    "                # Save the DataFrame as .xlsx with the new file name in the destination folder\n",
    "                new_xlsx_path = os.path.join(destination_folder_path, new_file_name)\n",
    "                combined_df.to_excel(new_xlsx_path, index=False)\n",
    "                \n",
    "                # Append the path of the converted .xlsx file to the list\n",
    "                converted_file_paths.append(new_xlsx_path)\n",
    "\n",
    "                # Use regex to parse the file name and extract the letter and number components\n",
    "                match = re.search(pattern, file_name)\n",
    "                if match:\n",
    "                    letter = match.group(1)\n",
    "                    number = letter + \"_\" + match.group(2)  # Combine letter and number\n",
    "                    letters.append(letter)\n",
    "                    numbers.append(number)\n",
    "                else:\n",
    "                    # Handle cases where the filename does not match the pattern\n",
    "                    letters.append(None)\n",
    "                    numbers.append(None)\n",
    "                \n",
    "                # Append the original .xls file path to the list\n",
    "                xls_paths.append(xls_path)\n",
    "\n",
    "                print(f\"Converted '{file_name}' to '{new_file_name}' and saved to destination folder\")\n",
    "\n",
    "# Create a DataFrame containing the list of converted file paths, parsed components, and original .xls paths\n",
    "data = {\n",
    "    'code': letters,\n",
    "    'project_id': numbers,\n",
    "    'original_path': xls_paths  # Add the original .xls paths to the DataFrame\n",
    "}\n",
    "\n",
    "converted_file_paths_df = pd.DataFrame(data)\n",
    "\n",
    "# Create empty list to store project names\n",
    "project_names = []\n",
    "\n",
    "# Iterate over the converted .xlsx paths to extract project names from 'P2'\n",
    "for xlsx_path in converted_file_paths:\n",
    "    # Load the Excel file to extract the project name from 'P2' in the new .xlsx file\n",
    "    wb = load_workbook(xlsx_path, data_only=True)\n",
    "    sheet = wb.active\n",
    "    project_name = sheet['P2'].value\n",
    "    project_names.append(project_name)\n",
    "\n",
    "# Add the project names to the DataFrame\n",
    "converted_file_paths_df['project_name'] = project_names\n",
    "\n",
    "# Display the DataFrame with the paths of converted files, parsed components, and original .xls paths\n",
    "print(\"\\nList of Converted File Paths, Parsed Components, Project Names, and Original .xls Paths:\")\n",
    "print(converted_file_paths_df)\n",
    "\n",
    "\n",
    "# Specify the path to save\n",
    "output_excel_path = r'\\\\fs109\\ES-Comm\\Commercial_Share_Folder\\Bright Rebates\\BPA Lighting Calculator Extraction Tool - Rosetta\\converted_files.xlsx'\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "converted_file_paths_df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(f\"Data saved to '{output_excel_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8984cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the appended_data.xlsx file\n",
    "appended_data_df = pd.read_excel('appended_data.xlsx')\n",
    "\n",
    "# Merge the two DataFrames based on the 'project_name' column\n",
    "merged_df = pd.merge(appended_data_df, converted_file_paths_df, on='project_name', how='left')\n",
    "\n",
    "\n",
    "##change column names\n",
    "\n",
    "# Rename columns in df_existing\n",
    "column_rename_dict = {\n",
    "    'est_annual_energy_savings':'est_annual_project_total_energy_savings',\n",
    "    'est_total_proj_install_costs':'est_total_project_cost',\n",
    "    'projcost':'final_total_project_cost',\n",
    "    'busbr_sav':'est_total_busbar_savings',\n",
    "    'wattred':'wattage_reduction',\n",
    "    'fedblg':'federal_building_flag',\n",
    "    'bpa_max_wtp':'BPA_willingness_to_pay',\n",
    "    'incentives':'incentive_notes',\n",
    "    'notes':'measure_notes',\n",
    "    'electric_interaction':'HVAC_interaction_factor',\n",
    "    'precond_decom_and_equip_kwh_savings_with_hvac':'Retrofit_and_Decom_Measure_Savings_HVAC_Ad',\n",
    "    'precond_equip_and_controls_kwh_savings_with_hvac_busbar': 'Retrofit_and_Decom_Measure_Savings_HVAC_Busbar_Adj',\n",
    "    'precond_total_measure_kwh':'baseline_total_fixture_kWh',\n",
    "    'precond_total_measure_kwh_with_hvac':'baseline_total_fixture_kWh_HVAC_Adj',\n",
    "    'proposed_total_measure_kwh_with_hvac': 'proposed_total_fixture_kWh_HVAC_Adj'\n",
    "    }\n",
    "\n",
    "\n",
    "merged_df.rename(columns=column_rename_dict, inplace=True)\n",
    "\n",
    "\n",
    "##QA TA contact name\n",
    "\n",
    "name_mapping = {\n",
    "    'Andy D':'Andy Deweyert',\n",
    "    'Bryan Gray':'Bryan Grey',\n",
    "    'Christina Henrickson':'Christina Henricksen',\n",
    "    'ED BRAY':'Ed Bray',\n",
    "    'self install': '',\n",
    "    'Self Install': '', \n",
    "    'Jeffery Gascoyne':'Jeff Gascoyne',\n",
    "    'Jerome Guissler': 'Jerome Geissler',\n",
    "    'Thomas Harwood':'Tom Harwood',\n",
    "    'Frederik Wouda Kuipers':'Fred Wouda Kuipers',\n",
    "    'self':'',\n",
    "    'Self install':'',\n",
    "    'JEFF GASCOYNE SR':'Jeff Gascoyne',\n",
    "    'Mark Niemanmarkn@mckinstry.com':'Mark Nieman'  \n",
    "    \n",
    "}\n",
    "\n",
    "# Use the replace method to replace values in the 'ta_organization' column\n",
    "merged_df['ta_contact_name'] = merged_df['ta_contact_name'].replace(name_mapping)\n",
    "\n",
    "merged_df['ta_contact_name'] = merged_df['ta_contact_name'].str.upper()\n",
    "\n",
    "\n",
    "# QA TA Org name\n",
    "rename_mapping = {\n",
    "    'BidEnergy': 'Bid Energy',\n",
    "    'Lumenal Lighting': 'Lumenal Lighting LLC',\n",
    "    'North Coast': 'North Coast Electric',\n",
    "    'North West Edison': 'Northwest Edison',\n",
    "    'Platt Electric': 'Platt Electric Supply',\n",
    "    'RAINIER LIGHTING AND ELECTRICAL SUPPLY': 'Rainier Lighting & Electric Supply',\n",
    "    'Seahurst Electic': 'Seahurst Electric',\n",
    "    'self ': 'Self Install',\n",
    "    'self':'Self Install',\n",
    "    'Sellf Install': 'Self Install',\n",
    "    'self install':'Self Install',\n",
    "    'Self install': 'Self Install',\n",
    "    'Stoneway Electrical Supply':'Stoneway Electric Supply',\n",
    "    'UNited Lamp ': 'United Lamp Supply',\n",
    "    'Wesco': 'WESCO Energy Solutions',\n",
    "    'Resound Energy': 'Resound Energy LLC',\n",
    "    'NW Edison': 'Northwest Edison',\n",
    "    'Source One Solutions': 'SourceOne Solutions',\n",
    "    'McKinstry': 'McKinstry Essention, LLC',\n",
    "    'Allied Electric': 'Allied Electric Corporation',\n",
    "    'Amaya': 'Amaya Electric',\n",
    "    'Ameya Eletric':'Amaya Eletric',\n",
    "    'Ault Electtric':'Ault Electric',\n",
    "    'Beyond Basic':'Beyond Basic Electric, In.',\n",
    "    'Capitol Light':'Capital Lighting',\n",
    "    'Creative Lighting':'Creative Lighting Solutions, Inc.',\n",
    "    'Danard Electric Inc.':'Danard Electric',\n",
    "    'DC Engineering Inc.':'DC Engineering',\n",
    "    'Eco Engineering.com':'Eco Engineering Inc.',\n",
    "    'Energy Management Collaborative':'Energy Management Collaborative LLC',\n",
    "    'Energy Management Collaborative llc':'Energy Management Collaborative LLC',\n",
    "    'Energy Retrofit co':'Energy Retrofit Co.',\n",
    "    'Energy Retrofit Co':'Energy Retrofit Co.',\n",
    "    'Graybar': 'Graybar Electric',\n",
    "    'Green Lighting LLC':'Green Lighting, LLC',\n",
    "    'Leidos Engineering LLC.':'Leidos Engineering, LLC',\n",
    "    'Leidos Engineering LLC':'Leidos Engineering, LLC',\n",
    "    'Lighitng & Power': 'Lighting & Power, Inc.',\n",
    "    'Lighting & Power Inc.': 'Lighting & Power, Inc',\n",
    "    'Lighting&Power, Inc':'Lighting & Power, Inc',\n",
    "    'Lumenal': 'Lumenal Lighting LLC',\n",
    "    'Lumenal Lighing formerly known as Light Doctor': 'Lumenal Lighting LLC',\n",
    "    'Lumenal Lighting':'Lumenal Lighting LLC',\n",
    "    'Lumenal Lighting formely known as Light Doctor':'Lumenal Lighting LLC',\n",
    "    'Lumenal Lighting formerly known as Light Doctor':'Lumenal Lighting LLC',\n",
    "    'Lumenal Lighting formerly known Light Doctor':'Lumenal Lighting LLC',\n",
    "    'Lumenal Lighting, LLC.':'Lumenal Lighting LLC',\n",
    "    'Lumenal Ligitng formerly known as Light Doctor':'Lumenal Lighting LLC',\n",
    "    'Lumenal Ligthing Formely known as Light Doctor':'Lumenal Lighting LLC',\n",
    "    'McKinstry Electric':'McKinstry Essention, LLC',\n",
    "    'Narrows Heating & AC, Inc.':'Narrows Heating & Air Conditioning',\n",
    "    'NW Lighting Solutions':'NW LIGHTING SOLUTIONS, LLC',\n",
    "    'NW LIGHTING SOLUTIONS,LLC':'NW LIGHTING SOLUTIONS, LLC',\n",
    "    'Olsen Electric':'Olsen Electric Inc.',\n",
    "    'Pacific Energy Concepts':'Pacific Energy Concepts, LLC',\n",
    "    'Pacific Lamp & Supply':'Pacific Lamp & Supply Co',\n",
    "    'PlanLED':'PlanLED Inc.',\n",
    "    'Platt':'Platt Electric Supply',\n",
    "    'Resound Energy Services':'Resound Energy Services, LLC',\n",
    "    'Resound Energy LLC':'Resound Energy Services, LLC',\n",
    "    'Resound Eneryg Services':'Resound Energy Services, LLC',\n",
    "    'Seahurst Electgric':'Seahurst Electric',\n",
    "    'Stoneay Electric Supply':'Stoneway Electric Supply',\n",
    "    'STONEWAY ELECTRIC':'Stoneway Electric Supply',\n",
    "    'Stoneway Electric Suppley':'Stoneway Electric Supply',\n",
    "    'StonewayElectric Supply':'Stoneway Electric Supply',\n",
    "    'Sylvania Lighting Solutions':'Sylvania Lighting Services',\n",
    "    'Tacoma Electric':'TACOMA ELECTRIC SUPPLY, INC',\n",
    "    'TACOMA ELECTRIC SUPPLY':'TACOMA ELECTRIC SUPPLY, INC',\n",
    "    'Tacoma Electric Supply':'TACOMA ELECTRIC SUPPLY, INC',\n",
    "    'United Lamp':'United Lamp Supply'\n",
    "    \n",
    "}\n",
    "\n",
    "# Use the replace method to replace values in the 'ta_organization' column\n",
    "merged_df['ta_organization'] = merged_df['ta_organization'].replace(rename_mapping)\n",
    "\n",
    "#everything to upper case\n",
    "\n",
    "merged_df['ta_organization'] = merged_df['ta_organization'].str.upper() \n",
    "\n",
    "# Display the DataFrame with the updated 'ta_organization' column\n",
    "print(merged_df['ta_organization'])\n",
    "\n",
    "print(f\"Merged data saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9268673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns to move and their new positions\n",
    "columns_to_move = ['mailing_full_address', 'project/site_full_address']\n",
    "new_positions = [1, 2]\n",
    "\n",
    "# Get the list of all columns in the DataFrame\n",
    "columns = merged_df.columns.tolist()\n",
    "\n",
    "# Iterate over the columns to move and their new positions\n",
    "for col, pos in zip(columns_to_move, new_positions):\n",
    "    columns.remove(col)  # Remove the column from its current position\n",
    "    columns.insert(pos, col)  # Insert the column at the new position\n",
    "\n",
    "# Create a new DataFrame with the columns reordered\n",
    "merged_df = merged_df[columns]\n",
    "\n",
    "# Display the modified DataFrame\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040524f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop one or more columns\n",
    "columns_to_drop = ['tpu_contact_phone', 'tpu_email', 'ta_contact_phone', 'est_energy_savings_(%)',\n",
    "                  'totcred', 'status', 'existing', 'proposed', 'blank_column', 'kw_for_table', 'proposed_lamp_model_number',\n",
    "                  'proposed_ballast_model_number', 'no_controls', 'number_of_errors','existing_mml_row', 'proposed_mml_row',\n",
    "                   'nonstandard_incentive_rates', 'completion_date' \n",
    "                  ]  # List of columns to drop\n",
    "\n",
    "# Use the drop method to drop the specified columns\n",
    "merged_df = merged_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a894e315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to save the merged DataFrame as a new Excel file\n",
    "output_merged_excel_path = r'\\\\fs109\\ES-Comm\\Commercial_Share_Folder\\Bright Rebates\\BPA Lighting Calculator Extraction Tool - Rosetta\\lc_final_draft_v0.xlsx'\n",
    "\n",
    "# Save the merged DataFrame to a new Excel file\n",
    "merged_df.to_excel(output_merged_excel_path, index=False)\n",
    "\n",
    "print(f\"Merged data saved to '{output_merged_excel_path}'. This is the final dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
